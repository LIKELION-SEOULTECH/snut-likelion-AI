import pandas as pd
import torch
from sentence_transformers import (
    SentenceTransformer,
    InputExample,
    losses,
    evaluation,
    util,
)
from torch.utils.data import DataLoader
from itertools import combinations

# 1. ë°ì´í„° ë¡œë”©
df = pd.read_excel("E:/star/BabyLION/chatbot/chatbot_augmented.xlsx")
df = df[["ì§ˆë¬¸", "ë‹µë³€"]].dropna()

# 2. ê°™ì€ ë‹µë³€ì„ ê³µìœ í•˜ëŠ” ì§ˆë¬¸ ê·¸ë£¹ì—ì„œ ìœ ì‚¬ ìŒ ìƒì„±
qa_pairs = []
for answer, group in df.groupby("ë‹µë³€"):
    questions = group["ì§ˆë¬¸"].tolist()
    for q1, q2 in combinations(questions, 2):
        qa_pairs.append((q1, q2))

# 3. InputExampleë¡œ ë³€í™˜
train_examples = [InputExample(texts=[q1, q2]) for q1, q2 in qa_pairs]

# 4. ë””ë°”ì´ìŠ¤ ì„¤ì • (CUDA ì‚¬ìš© ê°€ëŠ¥ ì‹œ CUDAë¡œ)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("ğŸ”¥ ì‚¬ìš© ë””ë°”ì´ìŠ¤:", device)

# 5. ëª¨ë¸ ë¡œë”© ë° ë””ë°”ì´ìŠ¤ ì´ë™
model = SentenceTransformer("snunlp/KR-SBERT-V40K-klueNLI-augSTS")
model = model.to(device)

# 6. DataLoader ë° Loss êµ¬ì„±
train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)
train_loss = losses.MultipleNegativesRankingLoss(model)

# 7. í‰ê°€ì ì„¤ì • (ì¼ë¶€ ìƒ˜í”Œë§Œ ì‚¬ìš©)
eval_examples = train_examples[:20]
evaluator = evaluation.EmbeddingSimilarityEvaluator.from_input_examples(
    eval_examples, name="sbert-eval"
)

# 8. íŒŒì¸íŠœë‹
model.fit(
    train_objectives=[(train_dataloader, train_loss)],
    evaluator=evaluator,
    epochs=3,
    warmup_steps=10,
    show_progress_bar=True,
)

# 9. ëª¨ë¸ ì €ì¥ (ëª…ì‹œì )
model.save("./sbert_finetuned")
print("âœ… SBERT íŒŒì¸íŠœë‹ ì™„ë£Œ ë° ì €ì¥ë¨: ./sbert_finetuned")

print("âœ… SBERT íŒŒì¸íŠœë‹ ì™„ë£Œ ë° ì €ì¥ë¨: ./sbert_finetuned")

# 10. ìœ ì‚¬ë„ í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    print("\nğŸ“ ìœ ì‚¬ë„ í…ŒìŠ¤íŠ¸ ì˜ˆì œ")

    model = SentenceTransformer("./sbert_finetuned")
    model = model.to(device)

    print("í˜„ì¬ ëª¨ë¸ì´ ë¡œë“œëœ ë””ë°”ì´ìŠ¤:", model.device)
    print("CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€:", torch.cuda.is_available())

    query1 = "ì„¸ì…˜ ê¼­ ë‚˜ê°€ì•¼ í•´ìš”?"
    query2 = "ì •ê¸° ì„¸ì…˜ ë¶ˆì°¸í•˜ë©´ ì•ˆ ë˜ë‚˜ìš”?"

    embeddings = model.encode([query1, query2], convert_to_tensor=True, device=device)
    score = util.cos_sim(embeddings[0], embeddings[1])
    print(f"'{query1}' â†” '{query2}' ìœ ì‚¬ë„ ì ìˆ˜:", round(score.item(), 4))
